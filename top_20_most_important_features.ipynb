{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ee7ac7-71fe-4a9a-970f-d2cbc60baec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "import nibabel as nib\n",
    "from scipy.ndimage import center_of_mass\n",
    "from nilearn.plotting import plot_connectome\n",
    "\n",
    "# LOAD DATA \n",
    "X_fc = np.load(\"cc200_fc_X_children.npy\")\n",
    "X_fc = np.nan_to_num(X_fc, nan=0.0)\n",
    "y = np.load(\"cc200_fc_y_children.npy\")\n",
    "\n",
    "pheno = pd.read_csv(\"Phenotypic_V1_0b_preprocessed1.csv\")\n",
    "pheno = pheno[(pheno[\"AGE_AT_SCAN\"] < 18) & pheno[\"DX_GROUP\"].isin([1, 2])].copy()\n",
    "pheno[\"label\"] = pheno[\"DX_GROUP\"] - 1\n",
    "pheno[\"SEX\"]   = pheno[\"SEX\"].map({1: 1, 2: 0})\n",
    "pheno[\"FIQ\"]   = pheno[\"FIQ\"].fillna(pheno[\"FIQ\"].mean())\n",
    "pheno[\"AGE_AT_SCAN\"] = pheno[\"AGE_AT_SCAN\"].fillna(pheno[\"AGE_AT_SCAN\"].mean())\n",
    "pheno[\"SITE_ID\"]      = LabelEncoder().fit_transform(pheno[\"SITE_ID\"])\n",
    "\n",
    "# Match and preprocess\n",
    "subject_ids = [f.split(\"_rois\")[0] for f in os.listdir(\"nyu_rois\") if f.endswith(\".1D\")]\n",
    "pheno = pheno[pheno[\"FILE_ID\"].isin(subject_ids)].reset_index(drop=True)\n",
    "\n",
    "X_demo = pheno[[\"AGE_AT_SCAN\", \"SEX\", \"FIQ\", \"SITE_ID\"]].values\n",
    "X_demo = StandardScaler().fit_transform(X_demo)\n",
    "\n",
    "X_combined = np.hstack([X_fc[:len(X_demo)], X_demo])\n",
    "y_combined = pheno[\"label\"].values\n",
    "\n",
    "#SelectKBest\n",
    "selector = SelectKBest(score_func=f_classif, k=2500)\n",
    "X_selected = selector.fit_transform(X_combined, y_combined)\n",
    "mask = selector.get_support(indices=True)  # indices of selected features\n",
    "\n",
    "# Train model\n",
    "model = xgb.XGBClassifier(\n",
    "    n_estimators=150,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_selected, y_combined)\n",
    "\n",
    "# Feature importances\n",
    "importances = model.feature_importances_\n",
    "top_indices = np.argsort(importances)[-20:][::-1]\n",
    "top_values  = importances[top_indices]\n",
    "\n",
    "# Map feature indices to name\n",
    "feature_names = []\n",
    "for idx in mask[top_indices]:\n",
    "    if idx < 19900:\n",
    "        feature_names.append(f\"Conn {idx}\")\n",
    "    else:\n",
    "        feature_names.append([\"Age\",\"Sex\",\"FIQ\",\"Site\"][idx - 19900])\n",
    "\n",
    "# Plot top 20 bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(len(top_values)), top_values[::-1])\n",
    "plt.yticks(range(len(top_values)), feature_names[::-1])\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.title(\"Top 20 Features (XGBoost + SelectKBest)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Top_20_Features.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# TEXTUAL OUTPUT\n",
    "print(\"\\n Top 20 Most Important Features:\")\n",
    "for i, idx in enumerate(mask[top_indices]):\n",
    "    if idx < 19900:\n",
    "        name = f\"Conn {idx}\"\n",
    "    else:\n",
    "        name = [\"Age\",\"Sex\",\"FIQ\",\"Site\"][idx - 19900]\n",
    "    print(f\"{i+1:2d}. {name:<10} | Importance: {top_values[i]:.4f}\")\n",
    "\n",
    "# Lateralization of Top 20 Connections\n",
    "\n",
    "# Load CC200 atlas and extract centroids for each ROI label (1â€“200)\n",
    "atlas_img  = nib.load(\"cc200_roi_atlas.nii.gz\")\n",
    "atlas_data = atlas_img.get_fdata()\n",
    "roi_labels = np.unique(atlas_data)[1:].astype(int)  # skip 0 background\n",
    "\n",
    "centroids = {}\n",
    "for lbl in roi_labels:\n",
    "    centroids[lbl] = center_of_mass(atlas_data == lbl)\n",
    "\n",
    "# Build adjacency matrix for top-20 connections\n",
    "n_rois  = 200\n",
    "triu_i, triu_j = np.triu_indices(n_rois, k=1)\n",
    "adj     = np.zeros((n_rois, n_rois))\n",
    "\n",
    "for feat_idx, imp in zip(top_indices, top_values):\n",
    "    i = triu_i[feat_idx]\n",
    "    j = triu_j[feat_idx]\n",
    "    adj[i, j] = imp\n",
    "    adj[j, i] = imp\n",
    "\n",
    "# Prepare list of coords in MNI space\n",
    "# ROI labels in atlas are 1-based; our i,j indices are 0-based\n",
    "coords = [centroids.get(l+1, (0,0,0)) for l in range(n_rois)]\n",
    "\n",
    "# Plot connectome highlighting top connections\n",
    "from nilearn.plotting import plot_connectome\n",
    "\n",
    "plot_connectome(\n",
    "    adjacency_matrix=adj,\n",
    "    node_coords=coords,\n",
    "    edge_kwargs={'linewidth': 2.0, 'alpha': 0.7},\n",
    "    title=\"Top-20 Connections Lateralization\",\n",
    "    node_size=50\n",
    ")\n",
    "plt.savefig(\"Figure5_3_lateralization.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
